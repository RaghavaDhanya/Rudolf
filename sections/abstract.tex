\chapter*{Abstract\markboth{Abstract}{Abstract}}\label{ch:abstract}
\addcontentsline{toc}{chapter}{Abstract}

Current advances in Generative Adversial Networks allow us to obtain near realistic images of faces but it is still quite distinguishable from actual photographic images. The technology is also not very amiable to changes in the orientation of faces in Convolutional Neural Networks(CNN). Additionally, the amount of data required to train the network must be exhaustible, for example, in case different perspectives of a face are required the various perspectives must be explicitly present in the training data to achieve the result. Thus the network requires humongous amounts of data.
\par\bigskip
In this paper we propose a novel approach to accomplish the same results using CapsNet. CapsNet employs a dynamic routing algorithm which replaces the scalar-output feature detectors of the CNN with vector-output capsules. A capsule is essentially a group of neurons describing a specific part of obect or image. Active capsules at one level make predictions, via transformation matrices, for the instantiation parameters of
higher-level capsules. In essence, the CapsNet is the reverse of the common Computer Graphics pipeline where we convert objects to their renders. The CapsNet works from the pixel level and works up towards the object.
\par\bigskip
We propose that the amount of data required to train a comparable model is very small while it gives comparable, if not better, results. 